{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b294c0f-be54-46e1-9566-e52e55b3adf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done splitting dataset into train/val.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths to your raw image and label folders\n",
    "image_dir = 'NewYOLO/images'\n",
    "label_dir = 'NewYOLO/labels'\n",
    "\n",
    "# New output folders\n",
    "os.makedirs('NewYOLO/images/train', exist_ok=True)\n",
    "os.makedirs('NewYOLO/images/val', exist_ok=True)\n",
    "os.makedirs('NewYOLO/labels/train', exist_ok=True)\n",
    "os.makedirs('NewYOLO/labels/val', exist_ok=True)\n",
    "\n",
    "# Get all image filenames\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "\n",
    "# Shuffle and split\n",
    "random.seed(42)\n",
    "random.shuffle(image_files)\n",
    "split_idx = int(0.8 * len(image_files))\n",
    "train_files = image_files[:split_idx]\n",
    "val_files = image_files[split_idx:]\n",
    "\n",
    "# Helper to move image + label\n",
    "def move_files(files, split):\n",
    "    for img_file in files:\n",
    "        base = os.path.splitext(img_file)[0]\n",
    "        label_file = base + '.txt'\n",
    "\n",
    "        # Move image\n",
    "        shutil.move(os.path.join(image_dir, img_file), f'NewYOLO/images/{split}/{img_file}')\n",
    "\n",
    "        # Move label (only if it exists)\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        if os.path.exists(label_path):\n",
    "            shutil.move(label_path, f'NewYOLO/labels/{split}/{label_file}')\n",
    "\n",
    "# Run moves\n",
    "move_files(train_files, 'train')\n",
    "move_files(val_files, 'val')\n",
    "\n",
    "print(\"‚úÖ Done splitting dataset into train/val.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3435caf1-c6c0-4321-89f7-37c681d11328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.107 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.101 üöÄ Python-3.8.13 torch-2.2.2 CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=measure_data.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/aarongordon/runs/detect/train6\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/aarongordon/Sheet_Music/project-2-at-2025-04-07-02-05-fce\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/aarongordon/Sheet_Music/project-2-at-2025-04-07-02-05-fce4aa76/images/train/118dccee-The_Real_Book_1-310.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0187]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/aarongordon/Sheet_Music/project-2-at-2025-04-07-02-05-fce4aa76/images/train/54178c6e-The_Real_Book_1-020.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1399      1.1584      1.1214]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/aarongordon/Sheet_Music/project-2-at-2025-04-07-02-05-fce4aa76/images/train/c8d18347-The_Real_Book_1-301.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2342]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/aarongordon/Sheet_Music/project-2-at-2025-04-07-02-05-fce4a\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /Users/aarongordon/Sheet_Music/project-2-at-2025-04-07-02-05-fce4aa76/images/val/3957efec-The_Real_Book_1-027.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2022      1.3285]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/aarongordon/runs/detect/train6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/aarongordon/runs/detect/train6\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      2.289      3.348      2.019        298        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214     0.0267      0.224     0.0237    0.00673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.922      3.315      1.789        298        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214     0.0439      0.369     0.0438     0.0171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/50         0G      1.684      3.049      1.584        249        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214     0.0617      0.519      0.084     0.0383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/50         0G       1.42      2.874      1.419        200        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214     0.0978      0.822      0.167     0.0897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      1.193      2.528      1.272        226        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.116      0.972      0.227      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       6/50         0G      1.147      2.342       1.21        295        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.118      0.991      0.625      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/50         0G      1.078      1.972       1.11        245        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.914      0.399       0.78      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       8/50         0G      1.001      1.724      1.074        195        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.922      0.606      0.818      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       9/50         0G      1.067      1.475      1.071        243        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.911      0.678      0.841      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      10/50         0G     0.9849      1.311      1.036        198        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.931      0.696      0.886       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      11/50         0G      1.071      1.265      1.061        343        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.933      0.711      0.918      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      12/50         0G      1.032      1.172      1.037        260        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.923      0.779      0.926      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      13/50         0G     0.9794      1.088      1.027        322        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214       0.91      0.896      0.939      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G     0.9503      1.008      1.018        217        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.919      0.907      0.958      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      15/50         0G     0.9788      1.029      1.059        226        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.919      0.907      0.958      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      16/50         0G     0.9358      1.025      1.027        330        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.952      0.931      0.975      0.711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      17/50         0G     0.8285     0.9236     0.9799        226        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.945      0.911      0.973      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      18/50         0G     0.8707     0.9168      1.014        251        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.945      0.911      0.973      0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G     0.9284     0.8857      1.017        227        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214       0.94      0.882      0.962      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      20/50         0G     0.8746     0.8686      1.014        287        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214       0.91      0.855      0.928      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      21/50         0G     0.8704     0.8582      1.001        314        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214       0.91      0.855      0.928      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      22/50         0G     0.8331     0.8185      1.003        239        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214       0.91       0.85       0.92      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      23/50         0G     0.8702     0.9238      1.013        272        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214       0.91       0.85       0.92      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      24/50         0G     0.8208     0.8826      1.001        170        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.929      0.902      0.954      0.708\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      25/50         0G     0.9031      0.766      1.015        225        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.929      0.902      0.954      0.708\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      26/50         0G     0.8289     0.8232     0.9949        178        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.928      0.963       0.98      0.748\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      27/50         0G     0.8586     0.8442      0.994        332        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.928      0.963       0.98      0.748\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      28/50         0G     0.8309     0.8166     0.9751        231        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.976      0.948      0.988      0.773\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      29/50         0G     0.8635     0.7696     0.9875        259        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.976      0.948      0.988      0.773\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      30/50         0G     0.8181     0.7407      0.985        295        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.976      0.948      0.988      0.773\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      31/50         0G     0.8362     0.8419     0.9883        173        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214       0.98      0.981      0.992      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      32/50         0G     0.8015     0.7418     0.9702        288        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214       0.98      0.981      0.992      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      33/50         0G     0.7888     0.7803      0.983        184        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.997      0.981      0.994      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G      0.813     0.7435     0.9673        344        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.997      0.981      0.994      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      35/50         0G     0.8825      0.806      1.004        295        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.997      0.981      0.994      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      36/50         0G     0.7578     0.7059     0.9708        239        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.996      0.986      0.995      0.784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      37/50         0G     0.7709      0.691      0.962        215        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.996      0.986      0.995      0.784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      38/50         0G     0.7856      0.774     0.9735        260        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.996      0.986      0.995      0.784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      39/50         0G     0.7914     0.7295     0.9753        185        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.997      0.986      0.995      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      40/50         0G     0.7585     0.7047     0.9657        200        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.997      0.986      0.995      0.806\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      41/50         0G     0.7026     0.7328      0.928        161        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.997      0.986      0.995       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      42/50         0G     0.7393     0.8288     0.9491        135        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.997      0.986      0.995       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      43/50         0G     0.6876     0.6987      0.907        144        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.997      0.986      0.995       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      44/50         0G     0.6945     0.7133     0.9002        170        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.996      0.981      0.995        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      45/50         0G     0.6696     0.6569      0.902        191        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.996      0.981      0.995        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      46/50         0G       0.75     0.7352     0.9312        165        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.996      0.981      0.995        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      47/50         0G      0.657     0.6741     0.9051        160        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.996      0.981      0.995      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      48/50         0G     0.6815     0.6771     0.9106        150        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.996      0.981      0.995      0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G     0.6796     0.6883     0.9084        148        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214          1      0.986      0.995      0.808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      50/50         0G     0.6339     0.6514      0.891        143        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214          1      0.986      0.995      0.808\n",
      "\n",
      "50 epochs completed in 0.212 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from /Users/aarongordon/runs/detect/train6/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/aarongordon/runs/detect/train6/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/aarongordon/runs/detect/train6/weights/best.pt...\n",
      "Ultralytics 8.3.101 üöÄ Python-3.8.13 torch-2.2.2 CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6        214      0.997      0.986      0.995       0.81\n",
      "Speed: 2.4ms preprocess, 119.1ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/aarongordon/runs/detect/train6\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa76df514f0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.98605,     0.98605,     0.98605,     0.98605,\n",
       "            0.98605,     0.11353,     0.10092,    0.088304,    0.075689,    0.063074,    0.050459,    0.037845,     0.02523,    0.012615,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.21053,     0.21053,     0.21757,     0.24471,     0.30652,     0.37801,      0.4313,     0.48557,     0.52891,      0.5669,     0.59232,     0.62326,     0.65354,     0.67838,     0.70928,      0.7417,     0.76011,     0.79009,     0.80003,     0.80415,     0.81616,     0.82198,     0.82851,\n",
       "            0.83699,     0.85175,     0.85511,     0.85797,     0.86129,     0.86411,      0.8652,     0.87608,     0.87811,     0.88473,     0.88811,      0.8911,     0.89172,     0.89234,     0.89327,     0.89447,     0.90222,      0.9047,     0.90881,     0.91264,     0.91793,     0.91919,     0.92128,\n",
       "            0.92338,     0.92501,     0.92644,     0.92775,     0.93196,     0.93241,     0.93286,      0.9333,     0.93375,     0.93451,     0.93548,     0.94019,     0.94076,     0.94133,      0.9419,     0.94302,     0.94468,     0.94587,     0.95081,     0.95258,     0.95307,     0.95337,     0.95367,\n",
       "            0.95396,     0.95426,     0.95456,     0.95486,     0.95506,     0.95523,     0.95539,     0.95555,     0.95572,     0.95588,     0.95604,      0.9562,     0.95637,     0.95653,     0.95669,     0.95685,     0.95702,     0.95716,     0.95728,     0.95739,     0.95751,     0.95762,     0.95774,\n",
       "            0.95785,     0.95797,     0.95808,      0.9582,     0.95831,     0.95843,     0.95855,     0.95866,     0.95878,     0.95889,     0.95901,     0.95912,     0.95924,     0.95942,     0.95963,     0.95985,     0.96006,     0.96027,     0.96048,      0.9607,     0.96091,     0.96112,     0.96134,\n",
       "            0.96364,     0.96391,     0.96418,     0.96445,     0.96472,     0.96499,     0.96526,     0.96553,      0.9658,     0.96593,     0.96604,     0.96615,     0.96626,     0.96637,     0.96648,     0.96659,     0.96671,     0.96682,     0.96693,     0.96704,     0.96715,     0.96726,     0.96737,\n",
       "            0.96748,     0.96759,      0.9677,     0.96781,     0.96792,     0.96803,     0.96809,     0.96815,      0.9682,     0.96826,     0.96831,     0.96837,     0.96843,     0.96848,     0.96854,     0.96859,     0.96865,      0.9687,     0.96876,     0.96881,     0.96887,     0.96893,     0.96898,\n",
       "            0.96904,     0.96909,     0.96915,      0.9692,     0.96926,     0.96932,     0.96937,     0.96943,     0.96948,     0.96954,     0.96959,     0.96965,      0.9697,     0.96976,     0.96982,     0.96987,     0.96993,     0.96998,     0.97004,     0.97009,     0.97015,      0.9702,     0.97026,\n",
       "            0.97034,     0.97041,     0.97049,     0.97057,     0.97064,     0.97072,     0.97079,     0.97087,     0.97094,     0.97102,      0.9711,     0.97117,     0.97125,     0.97132,      0.9714,     0.97147,     0.97155,     0.97163,      0.9717,     0.97178,     0.97185,     0.97193,       0.972,\n",
       "            0.97208,     0.97216,     0.97223,     0.97231,     0.97238,     0.97246,     0.97254,     0.97262,     0.97271,     0.97279,     0.97288,     0.97296,     0.97305,     0.97313,     0.97322,      0.9733,     0.97339,     0.97347,     0.97355,     0.97364,     0.97372,     0.97381,     0.97389,\n",
       "            0.97398,     0.97406,     0.97415,     0.97423,     0.97431,      0.9744,     0.97448,     0.97457,     0.97465,     0.97474,     0.97486,     0.97497,     0.97508,      0.9752,     0.97531,     0.97542,     0.97554,     0.97565,     0.97576,     0.97588,     0.97599,      0.9761,     0.97622,\n",
       "            0.97633,     0.97644,     0.97656,     0.97667,     0.97678,      0.9769,     0.97698,     0.97702,     0.97707,     0.97711,     0.97715,      0.9772,     0.97724,     0.97729,     0.97733,     0.97737,     0.97742,     0.97746,      0.9775,     0.97755,     0.97759,     0.97764,     0.97768,\n",
       "            0.97772,     0.97777,     0.97781,     0.97785,      0.9779,     0.97794,     0.97799,     0.97803,     0.97807,     0.97812,     0.97816,      0.9782,     0.97825,     0.97829,     0.97834,     0.97838,     0.97842,     0.97847,     0.97851,     0.97855,      0.9786,     0.97864,     0.97869,\n",
       "            0.97873,     0.97877,     0.97882,     0.97886,      0.9789,     0.97895,     0.97899,     0.97903,     0.97908,     0.97912,     0.97917,     0.97921,     0.97943,     0.97967,     0.97992,     0.98017,     0.98041,     0.98066,      0.9809,     0.98115,     0.98139,     0.98154,     0.98163,\n",
       "            0.98172,     0.98181,     0.98191,       0.982,     0.98209,     0.98218,     0.98227,     0.98236,     0.98246,     0.98255,     0.98264,     0.98273,     0.98282,     0.98291,       0.983,      0.9831,     0.98319,     0.98328,     0.98337,     0.98346,     0.98355,     0.98364,     0.98374,\n",
       "            0.98413,     0.98462,     0.98511,      0.9856,     0.98605,     0.98608,      0.9861,     0.98613,     0.98616,     0.98619,     0.98621,     0.98624,     0.98627,      0.9863,     0.98632,     0.98635,     0.98638,     0.98641,     0.98643,     0.98646,     0.98649,     0.98652,     0.98654,\n",
       "            0.98657,      0.9866,     0.98662,     0.98665,     0.98668,     0.98671,     0.98673,     0.98676,     0.98679,     0.98682,     0.98684,     0.98687,      0.9869,     0.98693,     0.98695,     0.98698,     0.98701,     0.98704,     0.98706,     0.98709,     0.98712,     0.98715,     0.98717,\n",
       "             0.9872,     0.98723,     0.98725,     0.98728,     0.98731,     0.98734,     0.98736,     0.98739,     0.98742,     0.98745,     0.98747,      0.9875,     0.98753,     0.98756,     0.98758,     0.98761,     0.98764,     0.98767,     0.98769,     0.98772,     0.98775,     0.98777,      0.9878,\n",
       "            0.98783,     0.98786,     0.98788,     0.98791,     0.98794,     0.98797,     0.98799,     0.98802,     0.98805,     0.98808,      0.9881,     0.98813,     0.98816,     0.98818,     0.98821,     0.98824,     0.98827,     0.98829,     0.98832,     0.98834,     0.98833,     0.98832,     0.98831,\n",
       "             0.9883,     0.98829,     0.98828,     0.98827,     0.98825,     0.98824,     0.98823,     0.98822,     0.98821,      0.9882,     0.98819,     0.98818,     0.98817,     0.98815,     0.98814,     0.98813,     0.98812,     0.98811,      0.9881,     0.98809,     0.98808,     0.98806,     0.98805,\n",
       "            0.98804,     0.98803,     0.98802,     0.98801,       0.988,     0.98799,     0.98798,     0.98796,     0.98795,     0.98794,     0.98793,     0.98792,     0.98791,      0.9879,     0.98789,     0.98787,     0.98786,     0.98785,     0.98784,     0.98783,     0.98782,     0.98781,      0.9878,\n",
       "            0.98779,     0.98777,     0.98776,     0.98775,     0.98774,     0.98773,     0.98772,     0.98771,      0.9877,     0.98768,     0.98767,     0.98766,     0.98765,     0.98764,     0.98763,     0.98762,     0.98761,      0.9876,     0.98758,     0.98757,     0.98756,     0.98755,     0.98754,\n",
       "            0.98753,     0.98752,     0.98751,     0.98749,     0.98748,     0.98747,     0.98746,     0.98745,     0.98744,     0.98743,     0.98742,     0.98741,     0.98739,     0.98738,     0.98737,     0.98736,     0.98735,     0.98734,     0.98733,     0.98732,      0.9873,     0.98729,     0.98728,\n",
       "            0.98727,     0.98726,     0.98725,     0.98724,     0.98723,     0.98722,      0.9872,     0.98719,     0.98718,     0.98717,     0.98716,     0.98715,     0.98714,     0.98713,     0.98711,      0.9871,     0.98709,     0.98708,     0.98707,     0.98706,     0.98705,     0.98704,     0.98702,\n",
       "            0.98701,       0.987,     0.98699,     0.98698,     0.98697,     0.98696,     0.98695,     0.98694,     0.98692,     0.98691,      0.9869,     0.98689,     0.98688,     0.98687,     0.98686,     0.98685,     0.98683,     0.98682,     0.98681,      0.9868,     0.98679,     0.98678,     0.98677,\n",
       "            0.98676,     0.98675,     0.98673,     0.98672,     0.98671,      0.9867,     0.98669,     0.98668,     0.98667,     0.98666,     0.98664,     0.98663,     0.98662,     0.98661,      0.9866,     0.98659,     0.98658,     0.98657,     0.98655,     0.98654,     0.98653,     0.98652,     0.98651,\n",
       "             0.9865,     0.98649,     0.98648,     0.98647,     0.98645,     0.98644,     0.98643,     0.98642,     0.98641,      0.9864,     0.98639,     0.98638,     0.98636,     0.98635,     0.98634,     0.98633,     0.98632,     0.98631,      0.9863,     0.98629,     0.98627,     0.98626,     0.98625,\n",
       "            0.98624,     0.98623,     0.98622,     0.98621,      0.9862,     0.98618,     0.98617,     0.98616,     0.98615,     0.98614,     0.98613,     0.98612,     0.98611,      0.9861,     0.98608,     0.98607,     0.98606,     0.98605,     0.98604,     0.98603,     0.98602,     0.98601,     0.98599,\n",
       "            0.98598,     0.98607,     0.98618,     0.98629,     0.98639,      0.9865,     0.98661,     0.98671,     0.98682,     0.98693,     0.98704,     0.98714,     0.98725,     0.98736,     0.98746,     0.98757,     0.98768,     0.98778,     0.98789,       0.988,      0.9881,     0.98821,     0.98831,\n",
       "            0.98838,     0.98846,     0.98853,     0.98861,     0.98868,     0.98876,     0.98883,     0.98891,     0.98898,     0.98906,     0.98913,     0.98921,     0.98928,     0.98936,     0.98943,     0.98951,     0.98958,     0.98966,     0.98973,     0.98981,     0.98988,     0.98996,     0.99003,\n",
       "            0.99011,     0.99018,     0.99025,     0.99033,      0.9904,     0.99048,     0.99055,     0.99062,     0.99064,     0.99067,     0.99069,     0.99072,     0.99074,     0.99077,     0.99079,     0.99082,     0.99085,     0.99087,      0.9909,     0.99092,     0.99095,     0.99097,       0.991,\n",
       "            0.99102,     0.99105,     0.99107,      0.9911,     0.99112,     0.99115,     0.99118,      0.9912,     0.99123,     0.99125,     0.99128,      0.9913,     0.99133,     0.99135,     0.99138,      0.9914,     0.99143,     0.99145,     0.99148,     0.99151,     0.99153,     0.99156,     0.99158,\n",
       "            0.99161,     0.99163,     0.99166,     0.99168,     0.99171,     0.99173,     0.99176,     0.99178,     0.99181,     0.99183,     0.99186,     0.99189,     0.99191,     0.99194,     0.99196,     0.99199,     0.99201,     0.99204,     0.99206,     0.99209,     0.99211,     0.99214,     0.99216,\n",
       "            0.99219,     0.99221,     0.99224,     0.99227,     0.99229,     0.99232,     0.99234,     0.99237,     0.99239,     0.99242,     0.99244,     0.99247,     0.99249,     0.99252,     0.99254,     0.99257,     0.99259,     0.99262,     0.99265,     0.99267,      0.9927,     0.99272,     0.99275,\n",
       "            0.99277,      0.9928,     0.99282,     0.99285,     0.99287,      0.9929,     0.99292,     0.99191,     0.98817,     0.98809,     0.98802,     0.98795,     0.98788,      0.9878,     0.98773,     0.98766,     0.98758,     0.98751,     0.98744,     0.98737,     0.98729,     0.98722,     0.98715,\n",
       "            0.98708,       0.987,     0.98693,     0.98686,     0.98679,     0.98671,     0.98664,     0.98657,     0.98649,     0.98642,     0.98635,     0.98628,      0.9862,     0.98613,     0.98606,     0.98598,     0.98591,     0.98584,     0.98568,     0.98523,     0.98477,     0.98431,     0.98386,\n",
       "             0.9834,     0.98328,     0.98317,     0.98307,     0.98296,     0.98286,     0.98275,     0.98265,     0.98254,     0.98244,     0.98233,     0.98223,     0.98212,     0.98202,     0.98191,     0.98181,     0.98171,      0.9816,      0.9815,     0.98139,     0.98129,     0.98118,     0.98108,\n",
       "            0.98097,      0.9799,     0.97863,     0.97626,     0.97584,     0.97558,     0.97533,     0.97507,     0.97481,     0.97455,      0.9743,     0.97404,     0.97378,     0.97273,     0.97108,     0.97087,     0.97065,     0.97044,     0.97023,     0.97001,      0.9698,     0.96958,     0.96937,\n",
       "            0.96915,     0.96894,     0.96872,     0.96814,     0.96744,     0.96674,     0.96352,     0.96262,     0.96173,     0.96097,     0.96047,     0.95996,     0.95945,     0.95894,     0.95586,     0.95496,     0.95406,     0.95341,     0.95309,     0.95276,     0.95244,     0.95212,     0.95179,\n",
       "            0.95147,     0.95115,     0.94704,     0.94446,     0.94309,     0.94274,     0.94239,     0.94204,     0.94168,     0.94133,     0.94097,     0.94062,     0.93859,     0.93715,     0.93601,     0.93499,     0.93415,     0.93331,     0.93251,     0.93183,     0.93115,     0.93047,     0.92925,\n",
       "            0.92709,     0.92603,     0.92498,     0.92214,     0.91771,     0.91463,     0.91042,      0.9086,     0.90468,     0.90376,     0.90284,     0.89398,     0.89266,     0.89133,     0.88735,     0.88568,     0.88354,     0.88099,     0.87638,     0.87569,       0.875,     0.87431,     0.87346,\n",
       "            0.87131,     0.86954,     0.86793,     0.86702,     0.86622,     0.86542,     0.86443,     0.86229,     0.85847,     0.85575,     0.84742,     0.84432,     0.84171,     0.83958,     0.83823,     0.83617,     0.83169,     0.82798,     0.81627,     0.81013,     0.80581,     0.80101,     0.79325,\n",
       "             0.7884,     0.78438,     0.78118,     0.77262,     0.76759,     0.76054,     0.74962,     0.74365,     0.74087,     0.73276,     0.71581,     0.70437,     0.68871,     0.67426,     0.66303,     0.64338,     0.61317,     0.59204,     0.57094,     0.55435,     0.52658,      0.4923,     0.46226,\n",
       "            0.41692,      0.3359,     0.29357,     0.24834,     0.19634,     0.12225,     0.07547,     0.01849,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.11778,     0.11778,      0.1222,      0.1396,     0.18131,     0.23357,     0.27565,      0.3216,     0.36076,     0.39706,     0.42246,     0.45465,     0.48761,     0.51579,     0.55238,     0.59274,     0.61661,     0.65706,     0.67092,     0.67675,     0.69393,     0.70239,     0.71198,\n",
       "            0.72459,       0.747,      0.7522,     0.75662,     0.76181,     0.76623,     0.76795,     0.78527,     0.78853,     0.79926,     0.80481,     0.80972,     0.81075,     0.81177,     0.81331,     0.81531,     0.82829,     0.83248,     0.83946,     0.84601,     0.85516,     0.85734,     0.86098,\n",
       "            0.86466,     0.86752,     0.87004,     0.87237,     0.87984,     0.88064,     0.88143,     0.88223,     0.88302,     0.88439,     0.88612,     0.89461,     0.89565,     0.89668,     0.89772,     0.89976,     0.90278,     0.90495,     0.91405,     0.91732,     0.91823,     0.91878,     0.91934,\n",
       "            0.91989,     0.92045,       0.921,     0.92156,     0.92194,     0.92225,     0.92255,     0.92285,     0.92316,     0.92346,     0.92377,     0.92407,     0.92437,     0.92468,     0.92498,     0.92528,     0.92559,     0.92586,     0.92607,     0.92629,     0.92651,     0.92672,     0.92694,\n",
       "            0.92715,     0.92737,     0.92759,      0.9278,     0.92802,     0.92824,     0.92845,     0.92867,     0.92889,      0.9291,     0.92932,     0.92954,     0.92975,     0.93009,     0.93049,     0.93089,      0.9313,      0.9317,      0.9321,      0.9325,      0.9329,      0.9333,      0.9337,\n",
       "            0.93806,     0.93857,     0.93908,     0.93959,     0.94011,     0.94062,     0.94113,     0.94164,     0.94216,     0.94241,     0.94262,     0.94283,     0.94304,     0.94325,     0.94346,     0.94368,     0.94389,      0.9441,     0.94431,     0.94452,     0.94473,     0.94494,     0.94516,\n",
       "            0.94537,     0.94558,     0.94579,       0.946,     0.94621,     0.94642,     0.94653,     0.94664,     0.94675,     0.94685,     0.94696,     0.94707,     0.94717,     0.94728,     0.94739,     0.94749,      0.9476,      0.9477,     0.94781,     0.94792,     0.94802,     0.94813,     0.94824,\n",
       "            0.94834,     0.94845,     0.94856,     0.94866,     0.94877,     0.94888,     0.94898,     0.94909,      0.9492,      0.9493,     0.94941,     0.94952,     0.94962,     0.94973,     0.94983,     0.94994,     0.95005,     0.95015,     0.95026,     0.95037,     0.95047,     0.95058,     0.95069,\n",
       "            0.95084,     0.95098,     0.95113,     0.95127,     0.95142,     0.95157,     0.95171,     0.95186,       0.952,     0.95215,     0.95229,     0.95244,     0.95259,     0.95273,     0.95288,     0.95302,     0.95317,     0.95331,     0.95346,     0.95361,     0.95375,      0.9539,     0.95404,\n",
       "            0.95419,     0.95433,     0.95448,     0.95463,     0.95477,     0.95492,     0.95508,     0.95524,      0.9554,     0.95557,     0.95573,     0.95589,     0.95606,     0.95622,     0.95638,     0.95655,     0.95671,     0.95687,     0.95703,      0.9572,     0.95736,     0.95752,     0.95769,\n",
       "            0.95785,     0.95801,     0.95818,     0.95834,      0.9585,     0.95867,     0.95883,     0.95899,     0.95916,     0.95933,     0.95955,     0.95977,        0.96,     0.96022,     0.96044,     0.96066,     0.96088,      0.9611,     0.96132,     0.96154,     0.96176,     0.96198,      0.9622,\n",
       "            0.96242,     0.96264,     0.96286,     0.96308,      0.9633,     0.96352,     0.96368,     0.96376,     0.96385,     0.96393,     0.96402,      0.9641,     0.96419,     0.96427,     0.96436,     0.96444,     0.96453,     0.96461,      0.9647,     0.96478,     0.96487,     0.96496,     0.96504,\n",
       "            0.96513,     0.96521,      0.9653,     0.96538,     0.96547,     0.96555,     0.96564,     0.96572,     0.96581,     0.96589,     0.96598,     0.96606,     0.96615,     0.96623,     0.96632,      0.9664,     0.96649,     0.96658,     0.96666,     0.96675,     0.96683,     0.96692,       0.967,\n",
       "            0.96709,     0.96717,     0.96726,     0.96734,     0.96743,     0.96751,      0.9676,     0.96768,     0.96777,     0.96785,     0.96794,     0.96803,     0.96845,     0.96894,     0.96942,      0.9699,     0.97038,     0.97086,     0.97134,     0.97182,      0.9723,     0.97259,     0.97277,\n",
       "            0.97295,     0.97313,     0.97331,     0.97349,     0.97367,     0.97385,     0.97403,     0.97421,     0.97439,     0.97457,     0.97475,     0.97493,     0.97511,     0.97529,     0.97547,     0.97565,     0.97583,     0.97601,     0.97619,     0.97637,     0.97655,     0.97673,     0.97691,\n",
       "            0.97769,     0.97866,     0.97963,      0.9806,     0.98149,     0.98154,      0.9816,     0.98165,      0.9817,     0.98176,     0.98181,     0.98187,     0.98192,     0.98198,     0.98203,     0.98208,     0.98214,     0.98219,     0.98225,      0.9823,     0.98236,     0.98241,     0.98246,\n",
       "            0.98252,     0.98257,     0.98263,     0.98268,     0.98274,     0.98279,     0.98285,      0.9829,     0.98295,     0.98301,     0.98306,     0.98312,     0.98317,     0.98323,     0.98328,     0.98333,     0.98339,     0.98344,      0.9835,     0.98355,     0.98361,     0.98366,     0.98372,\n",
       "            0.98377,     0.98382,     0.98388,     0.98393,     0.98399,     0.98404,      0.9841,     0.98415,      0.9842,     0.98426,     0.98431,     0.98437,     0.98442,     0.98448,     0.98453,     0.98459,     0.98464,     0.98469,     0.98475,      0.9848,     0.98486,     0.98491,     0.98497,\n",
       "            0.98502,     0.98507,     0.98513,     0.98518,     0.98524,     0.98529,     0.98535,      0.9854,     0.98545,     0.98551,     0.98556,     0.98562,     0.98567,     0.98573,     0.98578,     0.98584,     0.98589,     0.98594,       0.986,     0.98605,     0.98605,     0.98605,     0.98605,\n",
       "            0.98605,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,\n",
       "            0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98604,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,\n",
       "            0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98603,     0.98602,     0.98602,     0.98602,\n",
       "            0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,\n",
       "            0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98602,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,\n",
       "            0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,     0.98601,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,\n",
       "              0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,       0.986,\n",
       "              0.986,       0.986,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,\n",
       "            0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98599,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,\n",
       "            0.98598,     0.98616,     0.98637,     0.98659,      0.9868,     0.98702,     0.98723,     0.98745,     0.98766,     0.98788,     0.98809,     0.98831,     0.98852,     0.98873,     0.98895,     0.98916,     0.98938,     0.98959,     0.98981,     0.99002,     0.99024,     0.99045,     0.99065,\n",
       "             0.9908,     0.99095,      0.9911,     0.99125,      0.9914,     0.99155,      0.9917,     0.99185,     0.99201,     0.99216,     0.99231,     0.99246,     0.99261,     0.99276,     0.99291,     0.99306,     0.99321,     0.99336,     0.99351,     0.99366,     0.99381,     0.99396,     0.99411,\n",
       "            0.99426,     0.99442,     0.99457,     0.99472,     0.99487,     0.99502,     0.99517,      0.9953,     0.99535,      0.9954,     0.99545,      0.9955,     0.99555,      0.9956,     0.99565,     0.99571,     0.99576,     0.99581,     0.99586,     0.99591,     0.99596,     0.99601,     0.99606,\n",
       "            0.99612,     0.99617,     0.99622,     0.99627,     0.99632,     0.99637,     0.99642,     0.99648,     0.99653,     0.99658,     0.99663,     0.99668,     0.99673,     0.99678,     0.99683,     0.99689,     0.99694,     0.99699,     0.99704,     0.99709,     0.99714,     0.99719,     0.99725,\n",
       "             0.9973,     0.99735,      0.9974,     0.99745,      0.9975,     0.99755,      0.9976,     0.99766,     0.99771,     0.99776,     0.99781,     0.99786,     0.99791,     0.99796,     0.99801,     0.99807,     0.99812,     0.99817,     0.99822,     0.99827,     0.99832,     0.99837,     0.99843,\n",
       "            0.99848,     0.99853,     0.99858,     0.99863,     0.99868,     0.99873,     0.99878,     0.99884,     0.99889,     0.99894,     0.99899,     0.99904,     0.99909,     0.99914,      0.9992,     0.99925,      0.9993,     0.99935,      0.9994,     0.99945,      0.9995,     0.99955,     0.99961,\n",
       "            0.99966,     0.99971,     0.99976,     0.99981,     0.99986,     0.99991,     0.99996,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,\n",
       "            0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99065,     0.99063,     0.99061,     0.99059,\n",
       "            0.99056,     0.99054,     0.99052,      0.9905,     0.99047,     0.99045,     0.99043,     0.99041,     0.99039,     0.99036,     0.99034,     0.99032,      0.9903,     0.99028,     0.99025,     0.99023,     0.99021,     0.99019,     0.99017,     0.99014,     0.99012,      0.9901,     0.99008,\n",
       "            0.99005,     0.99003,     0.99001,     0.98999,     0.98997,     0.98994,     0.98992,      0.9899,     0.98988,     0.98986,     0.98983,     0.98981,     0.98979,     0.98977,     0.98974,     0.98972,      0.9897,     0.98968,     0.98966,     0.98963,     0.98961,     0.98959,     0.98957,\n",
       "            0.98955,     0.98952,      0.9895,     0.98948,     0.98946,     0.98944,     0.98941,     0.98939,     0.98937,     0.98935,     0.98932,      0.9893,     0.98928,     0.98926,     0.98924,     0.98921,     0.98919,     0.98917,     0.98915,     0.98913,      0.9891,     0.98908,     0.98906,\n",
       "            0.98904,     0.98901,     0.98899,     0.98897,     0.98895,     0.98893,      0.9889,     0.98888,     0.98886,     0.98884,     0.98882,     0.98879,     0.98877,     0.98875,     0.98873,     0.98871,     0.98868,     0.98866,     0.98864,     0.98862,     0.98859,     0.98857,     0.98855,\n",
       "            0.98853,     0.98851,     0.98848,     0.98846,     0.98844,     0.98842,      0.9884,     0.98837,     0.98835,     0.98833,     0.98831,     0.98829,     0.98826,     0.98824,     0.98822,      0.9882,     0.98817,     0.98815,     0.98813,     0.98811,     0.98809,     0.98806,     0.98804,\n",
       "            0.98802,       0.988,     0.98798,     0.98795,     0.98793,     0.98791,     0.98789,     0.98786,     0.98784,     0.98782,      0.9878,     0.98778,     0.98775,     0.98773,     0.98771,     0.98769,     0.98767,     0.98764,     0.98762,      0.9876,     0.98758,     0.98756,     0.98753,\n",
       "            0.98751,     0.98749,     0.98747,     0.98744,     0.98742,      0.9874,     0.98738,     0.98736,     0.98733,     0.98731,     0.98729,     0.98727,     0.98725,     0.98722,      0.9872,     0.98718,     0.98716,     0.98714,     0.98711,     0.98709,     0.98707,     0.98705,     0.98702,\n",
       "              0.987,     0.98698,     0.98696,     0.98694,     0.98691,     0.98689,     0.98687,     0.98685,     0.98683,      0.9868,     0.98678,     0.98676,     0.98674,     0.98671,     0.98669,     0.98667,     0.98665,     0.98663,      0.9866,     0.98658,     0.98656,     0.98654,     0.98652,\n",
       "            0.98649,     0.98647,     0.98645,     0.98643,     0.98641,     0.98638,     0.98636,     0.98634,     0.98632,     0.98629,     0.98627,     0.98625,     0.98623,     0.98621,     0.98618,     0.98616,     0.98614,     0.98612,      0.9861,     0.98607,     0.98605,     0.98603,     0.98601,\n",
       "            0.98599,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,\n",
       "            0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,\n",
       "            0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,\n",
       "            0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,\n",
       "            0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,\n",
       "            0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,\n",
       "            0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98598,     0.98396,     0.97661,     0.97647,     0.97632,     0.97618,     0.97604,      0.9759,     0.97576,     0.97562,     0.97547,     0.97533,     0.97519,     0.97505,     0.97491,     0.97477,     0.97462,\n",
       "            0.97448,     0.97434,      0.9742,     0.97406,     0.97392,     0.97377,     0.97363,     0.97349,     0.97335,     0.97321,     0.97306,     0.97292,     0.97278,     0.97264,      0.9725,     0.97236,     0.97221,     0.97207,     0.97177,     0.97088,        0.97,     0.96911,     0.96823,\n",
       "            0.96735,      0.9671,      0.9669,      0.9667,     0.96649,     0.96629,     0.96609,     0.96589,     0.96569,     0.96548,     0.96528,     0.96508,     0.96488,     0.96467,     0.96447,     0.96427,     0.96407,     0.96387,     0.96366,     0.96346,     0.96326,     0.96306,     0.96285,\n",
       "            0.96265,      0.9606,     0.95815,     0.95363,     0.95282,     0.95233,     0.95184,     0.95135,     0.95086,     0.95037,     0.94988,     0.94939,      0.9489,     0.94691,     0.94379,     0.94339,     0.94298,     0.94258,     0.94217,     0.94177,     0.94137,     0.94096,     0.94056,\n",
       "            0.94015,     0.93975,     0.93935,     0.93824,     0.93693,     0.93562,     0.92961,     0.92794,     0.92627,     0.92488,     0.92394,       0.923,     0.92205,     0.92111,     0.91545,     0.91381,     0.91216,     0.91097,     0.91038,     0.90979,      0.9092,     0.90861,     0.90802,\n",
       "            0.90743,     0.90684,     0.89941,     0.89476,     0.89232,     0.89168,     0.89105,     0.89042,     0.88979,     0.88916,     0.88853,      0.8879,     0.88428,     0.88174,     0.87972,     0.87792,     0.87644,     0.87496,     0.87355,     0.87236,     0.87117,     0.86998,     0.86784,\n",
       "            0.86409,     0.86225,     0.86042,     0.85553,     0.84794,     0.84268,     0.83557,     0.83251,     0.82596,     0.82442,     0.82289,     0.80828,     0.80613,     0.80397,     0.79751,     0.79482,     0.79138,     0.78729,     0.77996,     0.77887,     0.77778,     0.77668,     0.77535,\n",
       "            0.77196,      0.7692,     0.76667,     0.76526,     0.76401,     0.76276,     0.76123,     0.75792,     0.75204,     0.74787,     0.73524,     0.73059,     0.72668,     0.72352,     0.72152,     0.71846,     0.71187,     0.70646,     0.68957,     0.68085,     0.67478,     0.66807,     0.65735,\n",
       "            0.65071,     0.64525,     0.64094,     0.62948,     0.62283,      0.6136,     0.59951,     0.59192,      0.5884,     0.57824,      0.5574,     0.54366,     0.52521,     0.50859,     0.49592,     0.47425,     0.44214,      0.4205,     0.39952,     0.38346,     0.35739,     0.32652,     0.30061,\n",
       "            0.26336,     0.20185,     0.17204,     0.14178,     0.10886,    0.065107,    0.039215,   0.0093313,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.8286434030037646\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.81017])\n",
       "names: {0: 'measure'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9974503916799083, 'metrics/recall(B)': 0.985981308411215, 'metrics/mAP50(B)': 0.994860465116279, 'metrics/mAP50-95(B)': 0.8101748405468185, 'fitness': 0.8286434030037646}\n",
       "save_dir: PosixPath('/Users/aarongordon/runs/detect/train6')\n",
       "speed: {'preprocess': 2.379628166655342, 'inference': 119.12753166666334, 'loss': 0.00035116666670849855, 'postprocess': 3.77051366666592}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#might have to install this\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the small YOLOv8 model (you can also try yolov8s.pt or yolov8m.pt)\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Train the model\n",
    "model.train(data=\"measure_data.yaml\", epochs=50, imgsz=640, batch=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba27dfc9-a2c5-42bf-b51a-a86b92f1a7f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/detect/train/weights/best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns/detect/train/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get the model's backbone\u001b[39;00m\n\u001b[1;32m     10\u001b[0m backbone \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel[:\u001b[38;5;241m23\u001b[39m]  \u001b[38;5;66;03m# up to the neck\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ultralytics/models/yolo/model.py:37\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ultralytics/engine/model.py:148\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ultralytics/engine/model.py:290\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    287\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ultralytics/nn/tasks.py:1301\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;124;03m    Load a single model weights.\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;124;03m        (tuple): Tuple containing the model and checkpoint.\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1301\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ultralytics/nn/tasks.py:1206\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[1;32m   1205\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1206\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ultralytics/utils/patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/detect/train/weights/best.pt'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Get the model's backbone\n",
    "backbone = model.model.model[:23]  # up to the neck\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = cv2.imread(\"your-page.png\")\n",
    "img_resized = cv2.resize(img, (640, 640))\n",
    "img_tensor = torch.tensor(img_resized).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "\n",
    "# Pass through backbone\n",
    "with torch.no_grad():\n",
    "    features = backbone(img_tensor)[-1]  # e.g., last feature map\n",
    "\n",
    "# Global average pooling to get a single embedding vector\n",
    "embedding = features.mean(dim=[2, 3]).squeeze().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6751f704-47e1-4ead-bb86-3513e25912bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/Anthropology_1.png: 640x512 29 measures, 245.2ms\n",
      "Speed: 101.3ms preprocess, 245.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n"
     ]
    }
   ],
   "source": [
    "results = model(\"Anthropology_1.png\", conf=0.3)\n",
    "\n",
    "# Visualize\n",
    "results[0].show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c825fc8e-25da-4750-a0e4-79805e8bffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Processing song: How-Insensitive\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/How-Insensitive/How-Insensitive_1.png: 640x512 33 measures, 155.6ms\n",
      "Speed: 4.3ms preprocess, 155.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 33 measures saved in How-Insensitive/measures\n",
      "\n",
      "üìÑ Processing song: Prelude-to-a-Kiss\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Prelude-to-a-Kiss/Prelude-to-a-Kiss_1.png: 640x512 28 measures, 116.4ms\n",
      "Speed: 2.5ms preprocess, 116.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 28 measures saved in Prelude-to-a-Kiss/measures\n",
      "\n",
      "üìÑ Processing song: Do-You-Know-What-It-Means-To-Means-New-Orleans\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Do-You-Know-What-It-Means-To-Means-New-Orleans/Do-You-Know-What-It-Means-To-Means-New-Orleans_1.png: 640x512 36 measures, 164.1ms\n",
      "Speed: 3.6ms preprocess, 164.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 36 measures saved in Do-You-Know-What-It-Means-To-Means-New-Orleans/measures\n",
      "\n",
      "üìÑ Processing song: I-Mean-You\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/I-Mean-You/I-Mean-You_1.png: 640x512 28 measures, 170.5ms\n",
      "Speed: 3.0ms preprocess, 170.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 28 measures saved in I-Mean-You/measures\n",
      "\n",
      "üìÑ Processing song: Early-Autumn\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Early-Autumn/Early-Autumn_1.png: 640x512 29 measures, 116.2ms\n",
      "Speed: 2.3ms preprocess, 116.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 29 measures saved in Early-Autumn/measures\n",
      "\n",
      "üìÑ Processing song: I-Get-a-Kick-Out-of-You\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/I-Get-a-Kick-Out-of-You/I-Get-a-Kick-Out-of-You_1.png: 640x512 39 measures, 127.5ms\n",
      "Speed: 2.7ms preprocess, 127.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/I-Get-a-Kick-Out-of-You/I-Get-a-Kick-Out-of-You_2.png: 640x512 30 measures, 118.3ms\n",
      "Speed: 2.3ms preprocess, 118.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 69 measures saved in I-Get-a-Kick-Out-of-You/measures\n",
      "\n",
      "üìÑ Processing song: Minor-Mood\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Minor-Mood/Minor-Mood_1.png: 640x512 45 measures, 120.9ms\n",
      "Speed: 2.9ms preprocess, 120.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 45 measures saved in Minor-Mood/measures\n",
      "\n",
      "üìÑ Processing song: When-I-fall-in-love\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/When-I-fall-in-love/When-I-fall-in-love_1.png: 640x512 24 measures, 114.6ms\n",
      "Speed: 2.2ms preprocess, 114.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 24 measures saved in When-I-fall-in-love/measures\n",
      "\n",
      "üìÑ Processing song: Careless-Love\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Careless-Love/Careless-Love_1.png: 448x640 21 measures, 113.1ms\n",
      "Speed: 3.5ms preprocess, 113.1ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "‚úÖ Done: 21 measures saved in Careless-Love/measures\n",
      "\n",
      "üìÑ Processing song: Cherokee\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Cherokee/Cherokee_1.png: 640x512 55 measures, 119.5ms\n",
      "Speed: 2.4ms preprocess, 119.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 55 measures saved in Cherokee/measures\n",
      "\n",
      "üìÑ Processing song: Anthropology\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Anthropology/Anthropology_1.png: 640x512 29 measures, 110.6ms\n",
      "Speed: 3.3ms preprocess, 110.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 29 measures saved in Anthropology/measures\n",
      "\n",
      "üìÑ Processing song: Lady-Bird\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Lady-Bird/Lady-Bird_1.png: 640x512 16 measures, 116.5ms\n",
      "Speed: 2.5ms preprocess, 116.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 16 measures saved in Lady-Bird/measures\n",
      "\n",
      "üìÑ Processing song: Take-The-A-Train\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Take-The-A-Train/Take-The-A-Train_1.png: 640x512 27 measures, 137.0ms\n",
      "Speed: 2.5ms preprocess, 137.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 27 measures saved in Take-The-A-Train/measures\n",
      "\n",
      "üìÑ Processing song: Whisper-Not\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Whisper-Not/Whisper-Not_1.png: 640x512 46 measures, 120.0ms\n",
      "Speed: 2.2ms preprocess, 120.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 46 measures saved in Whisper-Not/measures\n",
      "\n",
      "üìÑ Processing song: All-Of-You\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/All-Of-You/All-Of-You_1.png: 640x512 36 measures, 116.7ms\n",
      "Speed: 2.5ms preprocess, 116.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 36 measures saved in All-Of-You/measures\n",
      "\n",
      "üìÑ Processing song: Moonglow\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Moonglow/Moonglow_1.png: 640x512 35 measures, 122.2ms\n",
      "Speed: 2.4ms preprocess, 122.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 35 measures saved in Moonglow/measures\n",
      "\n",
      "üìÑ Processing song: Satin-Doll\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Satin-Doll/Satin-Doll_1.png: 640x512 26 measures, 132.6ms\n",
      "Speed: 2.5ms preprocess, 132.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 26 measures saved in Satin-Doll/measures\n",
      "\n",
      "üìÑ Processing song: Meditation\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Meditation/Meditation_1.png: 640x512 29 measures, 118.9ms\n",
      "Speed: 2.1ms preprocess, 118.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 29 measures saved in Meditation/measures\n",
      "\n",
      "üìÑ Processing song: Once-I-Loved-O-Amor-Em-Paz\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Once-I-Loved-O-Amor-Em-Paz/Once-I-Loved-O-Amor-Em-Paz_1.png: 640x512 30 measures, 126.2ms\n",
      "Speed: 2.4ms preprocess, 126.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 30 measures saved in Once-I-Loved-O-Amor-Em-Paz/measures\n",
      "\n",
      "üìÑ Processing song: Whats-New\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Whats-New/Whats-New_1.png: 640x512 38 measures, 126.8ms\n",
      "Speed: 2.2ms preprocess, 126.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 38 measures saved in Whats-New/measures\n",
      "\n",
      "üìÑ Processing song: You-Dont-Know-What-Love-Is\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/You-Dont-Know-What-Love-Is/You-Dont-Know-What-Love-Is_1.png: 640x512 26 measures, 127.0ms\n",
      "Speed: 2.8ms preprocess, 127.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 26 measures saved in You-Dont-Know-What-Love-Is/measures\n",
      "\n",
      "üìÑ Processing song: You-Are-The-Sunshine-of-My-Life\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/You-Are-The-Sunshine-of-My-Life/You-Are-The-Sunshine-of-My-Life_1.png: 640x512 29 measures, 122.8ms\n",
      "Speed: 2.6ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 29 measures saved in You-Are-The-Sunshine-of-My-Life/measures\n",
      "\n",
      "üìÑ Processing song: Crazeology\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Crazeology/Crazeology_1.png: 640x512 26 measures, 123.7ms\n",
      "Speed: 2.3ms preprocess, 123.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 26 measures saved in Crazeology/measures\n",
      "\n",
      "üìÑ Processing song: Who-Can-I-Turn-To\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Who-Can-I-Turn-To/Who-Can-I-Turn-To_1.png: 640x512 42 measures, 125.5ms\n",
      "Speed: 2.4ms preprocess, 125.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 42 measures saved in Who-Can-I-Turn-To/measures\n",
      "\n",
      "üìÑ Processing song: Yardbird-Suite\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Yardbird-Suite/Yardbird-Suite_1.png: 640x512 24 measures, 126.6ms\n",
      "Speed: 2.4ms preprocess, 126.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 24 measures saved in Yardbird-Suite/measures\n",
      "\n",
      "üìÑ Processing song: Till-There-Was-You\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Till-There-Was-You/Till-There-Was-You_1.png: 640x512 31 measures, 126.8ms\n",
      "Speed: 2.4ms preprocess, 126.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 31 measures saved in Till-There-Was-You/measures\n",
      "\n",
      "üìÑ Processing song: Nature-Boy\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Nature-Boy/Nature-Boy_1.png: 640x512 34 measures, 125.4ms\n",
      "Speed: 2.4ms preprocess, 125.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 34 measures saved in Nature-Boy/measures\n",
      "\n",
      "üìÑ Processing song: Love-For-Sale\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Love-For-Sale/Love-For-Sale_1.png: 640x512 41 measures, 112.5ms\n",
      "Speed: 2.2ms preprocess, 112.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Love-For-Sale/Love-For-Sale_2.png: 640x512 27 measures, 124.3ms\n",
      "Speed: 2.5ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 68 measures saved in Love-For-Sale/measures\n",
      "\n",
      "üìÑ Processing song: Lover\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Lover/Lover_1.png: 640x512 44 measures, 127.1ms\n",
      "Speed: 2.3ms preprocess, 127.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 44 measures saved in Lover/measures\n",
      "\n",
      "üìÑ Processing song: Out-Of-Nowhere\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Out-Of-Nowhere/Out-Of-Nowhere_1.png: 640x512 24 measures, 128.2ms\n",
      "Speed: 2.8ms preprocess, 128.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 24 measures saved in Out-Of-Nowhere/measures\n",
      "\n",
      "üìÑ Processing song: Just-in-Time\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Just-in-Time/Just-in-Time_1.png: 640x512 35 measures, 123.0ms\n",
      "Speed: 2.4ms preprocess, 123.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 35 measures saved in Just-in-Time/measures\n",
      "\n",
      "üìÑ Processing song: On-a-Clear-Day-You-Can-See-Forever\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/On-a-Clear-Day-You-Can-See-Forever/On-a-Clear-Day-You-Can-See-Forever_1.png: 640x512 38 measures, 114.9ms\n",
      "Speed: 2.5ms preprocess, 114.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "‚úÖ Done: 38 measures saved in On-a-Clear-Day-You-Can-See-Forever/measures\n",
      "\n",
      "üìÑ Processing song: Youd-Be-So-Nice-to-Come-Home-To\n",
      "\n",
      "image 1/1 /Users/aarongordon/Sheet_Music/sheetmusic_pngs 2/Youd-Be-So-Nice-to-Come-Home-To/Youd-Be-So-Nice-to-Come-Home-To_1.png: 576x640 38 measures, 137.3ms\n",
      "Speed: 2.5ms preprocess, 137.3ms inference, 0.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "‚úÖ Done: 38 measures saved in Youd-Be-So-Nice-to-Come-Home-To/measures\n",
      "\n",
      "üìÑ Processing song: .ipynb_checkpoints\n",
      "‚úÖ Done: 0 measures saved in .ipynb_checkpoints/measures\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# === CONFIG ===\n",
    "ROOT_DIR = \"sheetmusic_pngs 2\"  # üëà Update with your root folder\n",
    "\n",
    "# === Helper function to sort boxes ===\n",
    "def sort_boxes_reading_order(boxes, y_thresh=40):\n",
    "    \"\"\"Sort YOLOv8 boxes top-to-bottom, then left-to-right within each row.\"\"\"\n",
    "    boxes = sorted(boxes, key=lambda b: b[1])  # sort by top y1\n",
    "    grouped_rows = []\n",
    "    current_row = []\n",
    "\n",
    "    for box in boxes:\n",
    "        if not current_row:\n",
    "            current_row.append(box)\n",
    "        elif abs(box[1] - current_row[-1][1]) < y_thresh:\n",
    "            current_row.append(box)\n",
    "        else:\n",
    "            grouped_rows.append(current_row)\n",
    "            current_row = [box]\n",
    "    if current_row:\n",
    "        grouped_rows.append(current_row)\n",
    "\n",
    "    # Now sort each row left to right (by x1)\n",
    "    sorted_boxes = []\n",
    "    for row in grouped_rows:\n",
    "        row_sorted = sorted(row, key=lambda b: b[0])\n",
    "        sorted_boxes.extend(row_sorted)\n",
    "\n",
    "    return sorted_boxes\n",
    "\n",
    "# === Walk through each song folder ===\n",
    "for song_folder in os.listdir(ROOT_DIR):\n",
    "    song_path = os.path.join(ROOT_DIR, song_folder)\n",
    "    if not os.path.isdir(song_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"üìÑ Processing song: {song_folder}\")\n",
    "    measure_counter = 1\n",
    "\n",
    "    # Clean or create 'measures' subfolder\n",
    "    measures_dir = os.path.join(song_path, \"measures\")\n",
    "    if os.path.exists(measures_dir):\n",
    "        shutil.rmtree(measures_dir)\n",
    "    os.makedirs(measures_dir, exist_ok=True)\n",
    "\n",
    "    # === Process each page (PNG) ===\n",
    "    for file in sorted(os.listdir(song_path)):\n",
    "        if not file.lower().endswith(\".png\"):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(song_path, file)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Infer page number from filename (fallback = 0)\n",
    "        try:\n",
    "            page_num = os.path.splitext(file)[0].split(\"_\")[-1]\n",
    "        except:\n",
    "            page_num = \"0\"\n",
    "\n",
    "        # Run YOLO detection\n",
    "        results = model(img_path, conf=0.3)\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "\n",
    "        # Sort boxes in reading order\n",
    "        sorted_boxes = sort_boxes_reading_order(boxes)\n",
    "\n",
    "        # === Crop and save each measure ===\n",
    "        for box in sorted_boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            filename = f\"measure_{measure_counter:03d}_page{page_num}.png\"\n",
    "            save_path = os.path.join(measures_dir, filename)\n",
    "            cv2.imwrite(save_path, crop)\n",
    "            measure_counter += 1\n",
    "\n",
    "    print(f\"‚úÖ Done: {measure_counter - 1} measures saved in {song_folder}/measures\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223828e8-5232-4cfe-b8bb-d21e0b2e1248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
